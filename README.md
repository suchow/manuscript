[![Build Status](https://travis-ci.com/suchow/test-manuscript.svg?branch=main)](https://travis-ci.com/suchow/test-manuscript)

# Understanding and Improving Human-bot Ecologies for Knowledge Generation

## Introduction

Knowledge generation happens online: Wikipedia articles are generated, 3D designs are shared, source code is forked and merged. Collectives are responsible for this generation. While collectives can be constituted entirely by humans, increasingly machines are part of the mix. For example, bots edit Wikipedia articles, generate 3D designs, and analyze source code. The machines are created by humans: Wikipedia editors create bots, platform owners create parametric model technologies, and developers create bots to enforce their own coding norms. Some of these environments have many machine agents; in Wikipedia there are over 1600 bots that contribute to articles at the same time as hundreds of thousands of editors. They donâ€™t do the same thing as humans, but they are often built to assist human editors and take over tasks that can be easily automatable, like discovering broken URLs, or tasks that are not so easy to automate but should be done quickly, such as reverting edits that bring down the quality of articles. These collectives of humans and bots form an ecology, in the sense that the agents evolve over time, the agents interact with each other, and the agents interact with an environment, including the artifacts that they create, modify, and recombine.

Since knowledge generation is at the heart of the economy, our education systems, and our culture, understanding how these ecologies work is important. Moreover, these ecologies have the potential to shift and change in dramatic ways, because the technologies that underlie bots are changing radically, at a different rate than the human components are changing. This project will seek to better understand current human bot ecologies in order to help us anticipate and shape the future.

The time to do this research is now, because there have been significant changes in bots. Bots are sometimes seen as agents that interact closely with humans. For example, many bots used in industry are constructed as hybrid systems with humans in the loop [11, 33, 75]. At the same time, there are different kinds of large scale bots that are more or less autonomous. For example, much of the recent machine learning research based on transformer architectures [77] (GPT-3 [4], BERT [16], roBERTa , XLnet [88]) are framed around testing the ability of machines to train on large amounts of human generated content and then generate new content autonomously. These systems are increasing in capability but are not yet capable of generating human-level wikipedia articles, musical scores, or source code. While they are tested in bench marks in comparison to other systems and to humans, these systems are usually used by humans in a more interactive manner: parameters are tuned [28], prompts are changed, outputs are copyedited. They are at the very least tuned, as in the system CTRL. And most environments are not using these very large and complex systems: Wikipedia bots, for example, often operate more like a search and replace regular expression than like a context-aware text summarizer. More generally, both complex AI and much simpler automated knowledge generation systems can be used as tools with some degree of autonomy [68], at the service of a collection of humans. As tools get written, they are added to the mix. As in any ecology, when a new tool is added it may change the environment. They may eclipse their previous versions. Techniques may eclipse earlier techniques, effectively killing off some bots. It is also possible that some techniques might be used together, as a kind of ensemble. Experience with such mixed environments can inform future development.

This leads to a set of research questions: what happens when humans and bots interact together over time? What do humans build, and what do they use? To what degree do humans change in reaction to bot introductions? More generally, what learns: humans? Bots? Or some other kind of emergent structure?  These questions are answered in the context of knowledge generation. Answering them involves not just observing but also experimenting.  Each of the two years will involve observational studies, bench studies, and field studies.
